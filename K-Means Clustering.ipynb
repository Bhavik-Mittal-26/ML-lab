{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5: K-Means Clustering on Spotify Data\n",
    "\n",
    "This experiment involves performing K-Means clustering on the Spotify dataset using two different methods:\n",
    "1. **Method 1: Using Scikit-Learn Library**\n",
    "2. **Method 2: Implementation from Scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../spotify.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features for clustering\n",
    "features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "            'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "X = df[features]\n",
    "\n",
    "# Handle missing values if any\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Preprocessed data shape:\", X_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Method 1: K-Means using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal K using Elbow Method\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying K-Means with optimal K (let's say K=5 based on common elbow results for this data)\n",
    "k = 5\n",
    "kmeans_model = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
    "y_kmeans = kmeans_model.fit_predict(X_scaled)\n",
    "\n",
    "df['cluster_sklearn'] = y_kmeans\n",
    "print(f\"Cluster counts (Sklearn):\\n{df['cluster_sklearn'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Method 2: K-Means Implementation from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchKMeans:\n",
    "    def __init__(self, n_clusters=5, max_iter=100, tol=1e-4):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.centroids = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Randomly initialize centroids\n",
    "        np.random.seed(42)\n",
    "        random_indices = np.random.permutation(X.shape[0])\n",
    "        self.centroids = X[random_indices[:self.n_clusters]]\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            # Assign clusters based on nearest centroid\n",
    "            labels = self._assign_clusters(X)\n",
    "            \n",
    "            # Update centroids with handling for empty clusters\n",
    "            new_centroids = []\n",
    "            for k in range(self.n_clusters):\n",
    "                cluster_points = X[labels == k]\n",
    "                if len(cluster_points) > 0:\n",
    "                    new_centroids.append(cluster_points.mean(axis=0))\n",
    "                else:\n",
    "                    # If cluster is empty, pick a random point from X as new centroid\n",
    "                    new_centroids.append(X[np.random.randint(0, X.shape[0])])\n",
    "            \n",
    "            new_centroids = np.array(new_centroids)\n",
    "            \n",
    "            # Check for convergence\n",
    "            if np.all(np.abs(new_centroids - self.centroids) < self.tol):\n",
    "                break\n",
    "            \n",
    "            self.centroids = new_centroids\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def _assign_clusters(self, X):\n",
    "        distances = np.sqrt(((X[:, np.newaxis] - self.centroids)**2).sum(axis=2))\n",
    "        return np.argmin(distances, axis=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self._assign_clusters(X)\n",
    "\n",
    "# Apply Scratch K-Means\n",
    "scratch_kmeans = ScratchKMeans(n_clusters=5)\n",
    "scratch_kmeans.fit(X_scaled)\n",
    "y_scratch = scratch_kmeans.predict(X_scaled)\n",
    "\n",
    "df['cluster_scratch'] = y_scratch\n",
    "print(f\"Cluster counts (Scratch):\\n{df['cluster_scratch'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PCA to reduce dimensions to 2D for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot Sklearn results\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['cluster_sklearn'], cmap='viridis', alpha=0.5)\n",
    "plt.title('K-Means (Scikit-Learn)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "\n",
    "# Plot Scratch results\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['cluster_scratch'], cmap='magma', alpha=0.5)\n",
    "plt.title('K-Means (From Scratch)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the two methods\n",
    "comparison = pd.crosstab(df['cluster_sklearn'], df['cluster_scratch'])\n",
    "print(\"Comparison Matrix (Sklearn vs Scratch):\")\n",
    "print(comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
